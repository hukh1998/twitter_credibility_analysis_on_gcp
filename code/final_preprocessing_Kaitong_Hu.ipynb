{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474a4ee9-cbba-4e84-a34a-53b9a7c78f6a",
   "metadata": {},
   "source": [
    "# Setting up environment and defining helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a3ae5e-0d52-4628-abe4-636a9da01434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6daec275-2235-40d9-a61b-1cd26b379653",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3d901cc-bde6-4726-bedc-2af453aa7173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:10) \n",
      "[GCC 10.3.0]\n",
      "3.1.3\n",
      "Requirement already satisfied: nltk in /opt/conda/miniconda3/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: click in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: joblib in /opt/conda/miniconda3/lib/python3.8/site-packages (from nltk) (1.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print(spark.version)\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.reset_option('display.max_rows')\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from itertools import compress \n",
    "import re\n",
    "from pyspark.ml.feature import MinHashLSH\n",
    "from pyspark.ml.feature import CountVectorizer,  IDF, CountVectorizerModel, Tokenizer, RegexTokenizer, StopWordsRemover\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import Row\n",
    "\n",
    "%pip install nltk -U\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "529c9f48-9fff-46bd-b9c1-f187e9c70acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f6bc99-68da-461c-ae21-86ee77186549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def list_blobs(bucket_name, folder_name):\n",
    "    gcs_client = storage.Client()\n",
    "    bucket = gcs_client.bucket(bucket_name)\n",
    "    blobs = list(bucket.list_blobs(prefix=folder_name))\n",
    "\n",
    "    for blob in blobs:\n",
    "        print(blob.name + '\\t' + str(blob.size))\n",
    "        \n",
    "        \n",
    "# Reading data from open bucket, avaible to all students\n",
    "bucket_read = 'msca-bdp-tweets'\n",
    "folder_read = 'final_project'\n",
    "\n",
    "# Saving results into individual bucket, students must update to their own bucket `msca-bdp-students-bucket` and use `CNET ID` as a folder prefix\n",
    "bucket_write = 'msca-bdp-students-bucket'\n",
    "folder_write = 'shared_data/kaitongh/filtered_dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e5a6ae-7b76-4045-b721-4a66b2cda564",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e6ed02-12e1-4e25-a145-04d5d585c951",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/07 01:57:46 WARN org.apache.spark.sql.execution.datasources.SharedInMemoryCache: Evicting cached table partition metadata from memory due to size constraints (spark.sql.hive.filesourcePartitionFileCacheSize = 262144000 bytes). This may impact query planning performance.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.51 s, sys: 871 ms, total: 4.38 s\n",
      "Wall time: 20min 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/07 02:14:52 WARN org.apache.spark.sql.catalyst.util.package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "path = 'gs://msca-bdp-tweets/final_project/'\n",
    "\n",
    "tweets_df = spark.read.json(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7451330d-5847-4395-ba9c-1e79732fb31b",
   "metadata": {},
   "source": [
    "#### Checking the schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c2ebbde-4903-40d3-8d8b-2c621fbcbe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d889d754-913a-4cf7-8420-542a96202d1b",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4746a734-1605-47b6-84fa-05e786a2b656",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Filtering out tweets that have no text\n",
    "\n",
    "tweets_df = tweets_df.filter(tweets_df.text.isNotNull())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1ab083-7ead-42c0-b65a-cd0a740b70a9",
   "metadata": {},
   "source": [
    "#### Selecting relevant columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3ff936a-5f9a-49a9-b9a8-8ccf0ccd1a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/02 19:58:26 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 35 for reason Container marked as failed: container_1670009274515_0001_01_000037 on host: hub-msca-bdp-dphub-students-kaitongh-sw-rk52.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n",
      "22/12/02 19:58:26 WARN org.apache.spark.scheduler.cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: Requesting driver to remove executor 37 for reason Container marked as failed: container_1670009274515_0001_01_000039 on host: hub-msca-bdp-dphub-students-kaitongh-sw-rk52.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n",
      "22/12/02 19:58:26 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 35 on hub-msca-bdp-dphub-students-kaitongh-sw-rk52.c.msca-bdp-students.internal: Container marked as failed: container_1670009274515_0001_01_000037 on host: hub-msca-bdp-dphub-students-kaitongh-sw-rk52.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n",
      "22/12/02 19:58:26 ERROR org.apache.spark.scheduler.cluster.YarnScheduler: Lost executor 37 on hub-msca-bdp-dphub-students-kaitongh-sw-rk52.c.msca-bdp-students.internal: Container marked as failed: container_1670009274515_0001_01_000039 on host: hub-msca-bdp-dphub-students-kaitongh-sw-rk52.c.msca-bdp-students.internal. Exit status: -100. Diagnostics: Container released on a *lost* node.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>coordinates</th><th>created_at</th><th>display_text_range</th><th>entities</th><th>extended_entities</th><th>extended_tweet</th><th>favorite_count</th><th>favorited</th><th>filter_level</th><th>geo</th><th>id</th><th>id_str</th><th>in_reply_to_screen_name</th><th>in_reply_to_status_id</th><th>in_reply_to_status_id_str</th><th>in_reply_to_user_id</th><th>in_reply_to_user_id_str</th><th>is_quote_status</th><th>lang</th><th>place</th><th>possibly_sensitive</th><th>quote_count</th><th>quoted_status</th><th>quoted_status_id</th><th>quoted_status_id_str</th><th>quoted_status_permalink</th><th>quoted_text</th><th>reply_count</th><th>retweet_count</th><th>retweeted</th><th>retweeted_from</th><th>retweeted_status</th><th>source</th><th>text</th><th>timestamp_ms</th><th>truncated</th><th>tweet_text</th><th>user</th><th>withheld_copyright</th><th>withheld_in_countries</th></tr>\n",
       "<tr><td>null</td><td>Tue Oct 04 01:43:...</td><td>null</td><td>{[], null, [], []...</td><td>null</td><td>null</td><td>0</td><td>false</td><td>low</td><td>null</td><td>1577112036168736768</td><td>1577112036168736768</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>false</td><td>en</td><td>null</td><td>null</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>RT</td><td>BulletinSport</td><td>{null, Mon Oct 03...</td><td>&lt;a href=&quot;http://t...</td><td>RT @BulletinSport...</td><td>1664847785404</td><td>false</td><td>The Martinsville ...</td><td>{false, Tue Jan 2...</td><td>null</td><td>null</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-----------+--------------------+------------------+--------------------+-----------------+--------------+--------------+---------+------------+----+-------------------+-------------------+-----------------------+---------------------+-------------------------+-------------------+-----------------------+---------------+----+-----+------------------+-----------+-------------+----------------+--------------------+-----------------------+-----------+-----------+-------------+---------+--------------+--------------------+--------------------+--------------------+-------------+---------+--------------------+--------------------+------------------+---------------------+\n",
       "|coordinates|          created_at|display_text_range|            entities|extended_entities|extended_tweet|favorite_count|favorited|filter_level| geo|                 id|             id_str|in_reply_to_screen_name|in_reply_to_status_id|in_reply_to_status_id_str|in_reply_to_user_id|in_reply_to_user_id_str|is_quote_status|lang|place|possibly_sensitive|quote_count|quoted_status|quoted_status_id|quoted_status_id_str|quoted_status_permalink|quoted_text|reply_count|retweet_count|retweeted|retweeted_from|    retweeted_status|              source|                text| timestamp_ms|truncated|          tweet_text|                user|withheld_copyright|withheld_in_countries|\n",
       "+-----------+--------------------+------------------+--------------------+-----------------+--------------+--------------+---------+------------+----+-------------------+-------------------+-----------------------+---------------------+-------------------------+-------------------+-----------------------+---------------+----+-----+------------------+-----------+-------------+----------------+--------------------+-----------------------+-----------+-----------+-------------+---------+--------------+--------------------+--------------------+--------------------+-------------+---------+--------------------+--------------------+------------------+---------------------+\n",
       "|       null|Thu Jun 02 22:12:...|              null|{[], null, [], []...|             null|          null|             0|    false|         low|null|1532485357295620110|1532485357295620110|                   null|                 null|                     null|               null|                   null|          false|  en| null|              null|          0|         null|            null|                null|                   null|       null|          0|            0|       RT|   RepSwalwell|{null, Thu Jun 02...|<a href=\"http://t...|RT @RepSwalwell: ...|1654207956037|    false|We are voting to ...|{false, Tue Apr 1...|              null|                 null|\n",
       "+-----------+--------------------+------------------+--------------------+-----------------+--------------+--------------+---------+------------+----+-------------------+-------------------+-----------------------+---------------------+-------------------------+-------------------+-----------------------+---------------+----+-----+------------------+-----------+-------------+----------------+--------------------+-----------------------+-----------+-----------+-------------+---------+--------------+--------------------+--------------------+--------------------+-------------+---------+--------------------+--------------------+------------------+---------------------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.limit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f7d32c-6945-4c0b-8052-337384039dd0",
   "metadata": {},
   "source": [
    "#### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d0c720-0791-40d3-bd65-e8b26439edbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>retweet_count</th></tr>\n",
       "<tr><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+\n",
       "|retweet_count|\n",
       "+-------------+\n",
       "|            0|\n",
       "+-------------+"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking the retweet_count column\n",
    "### there is only 0 in this column, we can't use this to calculate the total number of retweets\n",
    "tweets_df.select('retweet_count').distinct().limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e208723-c7de-46e8-b126-68efc1ff059b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "### limiting the sample size for faster eda \n",
    "sub = tweets_df.limit(100000).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e05693-e97e-4263-bcda-c41703a2daf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 40 columns):\n",
      " #   Column                     Non-Null Count   Dtype  \n",
      "---  ------                     --------------   -----  \n",
      " 0   coordinates                34 non-null      object \n",
      " 1   created_at                 100000 non-null  object \n",
      " 2   display_text_range         12722 non-null   object \n",
      " 3   entities                   100000 non-null  object \n",
      " 4   extended_entities          3806 non-null    object \n",
      " 5   extended_tweet             15603 non-null   object \n",
      " 6   favorite_count             100000 non-null  int64  \n",
      " 7   favorited                  100000 non-null  bool   \n",
      " 8   filter_level               100000 non-null  object \n",
      " 9   geo                        34 non-null      object \n",
      " 10  id                         100000 non-null  int64  \n",
      " 11  id_str                     100000 non-null  object \n",
      " 12  in_reply_to_screen_name    11894 non-null   object \n",
      " 13  in_reply_to_status_id      11538 non-null   float64\n",
      " 14  in_reply_to_status_id_str  11538 non-null   object \n",
      " 15  in_reply_to_user_id        11894 non-null   float64\n",
      " 16  in_reply_to_user_id_str    11894 non-null   object \n",
      " 17  is_quote_status            100000 non-null  bool   \n",
      " 18  lang                       100000 non-null  object \n",
      " 19  place                      517 non-null     object \n",
      " 20  possibly_sensitive         10496 non-null   object \n",
      " 21  quote_count                100000 non-null  int64  \n",
      " 22  quoted_status              7105 non-null    object \n",
      " 23  quoted_status_id           7118 non-null    float64\n",
      " 24  quoted_status_id_str       7118 non-null    object \n",
      " 25  quoted_status_permalink    7105 non-null    object \n",
      " 26  quoted_text                7105 non-null    object \n",
      " 27  reply_count                100000 non-null  int64  \n",
      " 28  retweet_count              100000 non-null  int64  \n",
      " 29  retweeted                  100000 non-null  object \n",
      " 30  retweeted_from             80601 non-null   object \n",
      " 31  retweeted_status           74638 non-null   object \n",
      " 32  source                     100000 non-null  object \n",
      " 33  text                       100000 non-null  object \n",
      " 34  timestamp_ms               100000 non-null  object \n",
      " 35  truncated                  100000 non-null  bool   \n",
      " 36  tweet_text                 100000 non-null  object \n",
      " 37  user                       100000 non-null  object \n",
      " 38  withheld_copyright         0 non-null       object \n",
      " 39  withheld_in_countries      10 non-null      object \n",
      "dtypes: bool(3), float64(3), int64(5), object(29)\n",
      "memory usage: 28.5+ MB\n"
     ]
    }
   ],
   "source": [
    "sub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "646d3666-51e2-4170-9518-5ee2ed9c02ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (None, Tue May 24 21:54:24 +0000 2022, [0, 140], ([], None, [], [Row(display_url='twitter.com/i/web/status/1…', expanded_url='https://twitter.com/i/web/status/1529219289005400064', indices=[117, 140], url='https://t.co/7XLz71jM8u')], []), None, ([0, 279], ([], [Row(additional_media_info=Row(description=None, embeddable=None, monetizable=False, title=None), description=None, display_url='pic.twitter.com/9fkJ13vWGd', expanded_url='https://twitter.com/ABC/status/1529219289005400064/video/1', id=1529219222970281984, id_str='1529219222970281984', indices=[280, 303], media_url='http://pbs.twimg.com/amplify_video_thumb/1529219222970281984/img/rr2UoSQsvksDKCP-.jpg', media_url_https='https://pbs.twimg.com/amplify_video_thumb/1529219222970281984/img/rr2UoSQsvksDKCP-.jpg', sizes=Row(large=Row(h=540, resize='fit', w=540), medium=Row(h=540, resize='fit', w=540), small=Row(h=540, resize='fit', w=540), thumb=Row(h=150, resize='crop', w=150)), source_status_id=None, source_status_id_str=None, source_user_id=None, source_user_id_str=None, type='video', url='https://t.co/9fkJ13vWGd', video_info=Row(aspect_ratio=[1, 1], duration_millis=139139, variants=[Row(bitrate=832000, content_type='video/mp4', url='https://video.twimg.com/amplify_video/1529219222970281984/vid/540x540/MmrXAltq2cciQ-kZ.mp4?tag=14'), Row(bitrate=None, content_type='application/x-mpegURL', url='https://video.twimg.com/amplify_video/1529219222970281984/pl/YvQ0AZRLakUNBgxt.m3u8?tag=14&container=fmp4'), Row(bitrate=432000, content_type='video/mp4', url='https://video.twimg.com/amplify_video/1529219222970281984/vid/320x320/rxHdmJnDUFhZGQwx.mp4?tag=14')]))], [], [], []), ([Row(additional_media_info=Row(description=None, embeddable=None, monetizable=False, title=None), description=None, display_url='pic.twitter.com/9fkJ13vWGd', expanded_url='https://twitter.com/ABC/status/1529219289005400064/video/1', id=1529219222970281984, id_str='1529219222970281984', indices=[280, 303], media_url='http://pbs.twimg.com/amplify_video_thumb/1529219222970281984/img/rr2UoSQsvksDKCP-.jpg', media_url_https='https://pbs.twimg.com/amplify_video_thumb/1529219222970281984/img/rr2UoSQsvksDKCP-.jpg', sizes=Row(large=Row(h=540, resize='fit', w=540), medium=Row(h=540, resize='fit', w=540), small=Row(h=540, resize='fit', w=540), thumb=Row(h=150, resize='crop', w=150)), source_status_id=None, source_status_id_str=None, source_user_id=None, source_user_id_str=None, type='video', url='https://t.co/9fkJ13vWGd', video_info=Row(aspect_ratio=[1, 1], duration_millis=139139, variants=[Row(bitrate=832000, content_type='video/mp4', url='https://video.twimg.com/amplify_video/1529219222970281984/vid/540x540/MmrXAltq2cciQ-kZ.mp4?tag=14'), Row(bitrate=None, content_type='application/x-mpegURL', url='https://video.twimg.com/amplify_video/1529219222970281984/pl/YvQ0AZRLakUNBgxt.m3u8?tag=14&container=fmp4'), Row(bitrate=432000, content_type='video/mp4', url='https://video.twimg.com/amplify_video/1529219222970281984/vid/320x320/rxHdmJnDUFhZGQwx.mp4?tag=14')]))],), “Why are you here?!\"\\n\\nA furious Sen. Chris Murphy demands answers from senators following Texas school shooting.\\n\\n“Why do you spend all this time running for the United States Senate...if your answer, is as the slaughter increases, as our kids run for their lives—we do nothing?” https://t.co/9fkJ13vWGd), 8422, False, low, None, 1529219289005400064, 1529219289005400064, None, None, None, None, None, False, en, None, False, 355, None, None, None, None, 217, 3008, False, None, <a href=\"http://www.snapstream.com\" rel=\"nofollow\">SnapStream TV Search</a>, “Why are you here?!\"\\n\\nA furious Sen. Chris Murphy demands answers from senators following Texas school shooting.\\n\\n“… https://t.co/7XLz71jM8u, True, (False, Sat Apr 04 12:40:32 +0000 2009, False, False, All the news and information you need to see, curated by the @ABC News team. Watch full ABC News broadcasts on @Hulu: http://abcn.ws/3bJ62RK, 44, 17508972, 488, True, 28785486, 28785486, False, 65598, New York City / Worldwide, ABC News, 6E8EB5, http://abs.twimg.com/images/themes/theme1/bg.png, https://abs.twimg.com/images/themes/theme1/bg.png, False, https://pbs.twimg.com/profile_banners/28785486/1505493568, http://pbs.twimg.com/profile_images/1453073578790948873/4bg2Xr0L_normal.jpg, https://pbs.twimg.com/profile_images/1453073578790948873/4bg2Xr0L_normal.jpg, 336699, FFFFFF, DDEEF6, 333333, True, False, ABC, 386269, regular, https://abcnews.go.com/, True, []), None, None)\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               None\n",
       "Name: retweeted_status, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking the retweeted_status column \n",
    "sub['retweeted_status'].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf7df2da-d75b-4b19-a36a-21639499f0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>retweet_count</th></tr>\n",
       "<tr><td>48</td></tr>\n",
       "<tr><td>5</td></tr>\n",
       "<tr><td>null</td></tr>\n",
       "<tr><td>36</td></tr>\n",
       "<tr><td>4</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+-------------+\n",
       "|retweet_count|\n",
       "+-------------+\n",
       "|          215|\n",
       "|         null|\n",
       "|         null|\n",
       "|            7|\n",
       "|          245|\n",
       "+-------------+"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.select('retweeted_status.retweet_count').limit(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bdbddde-bd79-44b6-930f-2b4a6d084122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>retweeted_from</th>\n",
       "      <th>retweeted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ABC: “Why are you here?!\"\\n\\nA furious Sen. Chris Murphy demands answers from senators following Texas school shooting.\\n\\n“Why do you spen…</td>\n",
       "      <td>ABC</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indiana High School Softball | Live Streaming\\nTBA vs Fishers\\nEastbrook vs Oak Hill\\nTBA vs Wabash\\nSouth Newton vs Cl… https://t.co/QvvQQUUOG8</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @jaketapper: Fifteen have been killed in a shooting at Robb elementary school, according to Governor Greg Abbott —  14 students and 1 te…</td>\n",
       "      <td>jaketapper</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Uvalde is just another reason why you should home school your kids. Exposing your kids to the degenerate version o… https://t.co/KiEpSzUJtf</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Josh_Moon: 14 dead elementary school kids. 14. Not from CRT. Or \"woke\" history. Which red states took great pains to ban. But from our…</td>\n",
       "      <td>Josh_Moon</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @Jim_Jordan: Last week we learned:\\n\\n-Hillary Clinton ordered the dissemination of the Trump/Alfa Bank hoax.\\n\\n-President Biden thanked NS…</td>\n",
       "      <td>Jim_Jordan</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @meganbang3: My son was not allowed to walk in his high school graduation yesterday because of his beaded cap and eagle feather. They wa…</td>\n",
       "      <td>meganbang3</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @jewishaction: We're horrified by the news of the shooting at Robb Elementary School in Uvalde, Texas.\\n\\n14 children and one teacher murd…</td>\n",
       "      <td>jewishaction</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @LRiddickESPN: Uh…question …WTF are those of you “in charge” that can make significant change happen in the name of safety ACTUALLY DOIN…</td>\n",
       "      <td>LRiddickESPN</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@TheUSASingers My daughter had a lockdown incident today at her school today hours before what happened in Texas😩 M… https://t.co/GdKqjKVjb2</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>RT @Gisele23935327: Who did not shoot up a school today?\\nA border crosser, transgender, or gay,\\nIt wasn’t Antifa, not BLM,\\nNot Hunter Biden…</td>\n",
       "      <td>Gisele23935327</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>RT @MichaelSteele: 14 children and a teacher have been killed in a shooting at an elementary school in Texas.  Again, another school shooti…</td>\n",
       "      <td>MichaelSteele</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RT @ABCPolitics: Sen. Chris Murphy delivers remarks on Uvalde, Texas elementary school shooting: “What are we doing? What are we doing?…Thi…</td>\n",
       "      <td>ABCPolitics</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RT @glowinasia: and if ur a non american saying some shit like i’m glad i’m not american or pulling the school shooting “jokes” during even…</td>\n",
       "      <td>glowinasia</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@iiTorchTv school shooting</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>RT @KaufmanAbrams: A horrific massacre at a Texas Grammar School. My children grown &amp;amp; have grand children even if I didn’t I Have said in p…</td>\n",
       "      <td>KaufmanAbrams</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RT @OccupyDemocrats: BREAKING NEWS: Texas’ gun-obsessed Governor Greg Abbott confirms that 14 children and two adults were shot dead by a m…</td>\n",
       "      <td>OccupyDemocrats</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RT @Meidas_Adrienne: If you want school shootings to stop then don’t don’t vote for a republican ever again.</td>\n",
       "      <td>Meidas_Adrienne</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RT @ABCPolitics: Sen. Chris Murphy delivers remarks on Uvalde, Texas elementary school shooting: “What are we doing? What are we doing?…Thi…</td>\n",
       "      <td>ABCPolitics</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RT @KingJames: My thoughts and prayers goes out to the families of love ones loss &amp;amp; injured at Robb Elementary School in Uvalde, TX! Like w…</td>\n",
       "      <td>KingJames</td>\n",
       "      <td>RT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                text  \\\n",
       "0   RT @ABC: “Why are you here?!\"\\n\\nA furious Sen. Chris Murphy demands answers from senators following Texas school shooting.\\n\\n“Why do you spen…   \n",
       "1   Indiana High School Softball | Live Streaming\\nTBA vs Fishers\\nEastbrook vs Oak Hill\\nTBA vs Wabash\\nSouth Newton vs Cl… https://t.co/QvvQQUUOG8   \n",
       "2       RT @jaketapper: Fifteen have been killed in a shooting at Robb elementary school, according to Governor Greg Abbott —  14 students and 1 te…   \n",
       "3       #Uvalde is just another reason why you should home school your kids. Exposing your kids to the degenerate version o… https://t.co/KiEpSzUJtf   \n",
       "4        RT @Josh_Moon: 14 dead elementary school kids. 14. Not from CRT. Or \"woke\" history. Which red states took great pains to ban. But from our…   \n",
       "5   RT @Jim_Jordan: Last week we learned:\\n\\n-Hillary Clinton ordered the dissemination of the Trump/Alfa Bank hoax.\\n\\n-President Biden thanked NS…   \n",
       "6       RT @meganbang3: My son was not allowed to walk in his high school graduation yesterday because of his beaded cap and eagle feather. They wa…   \n",
       "7     RT @jewishaction: We're horrified by the news of the shooting at Robb Elementary School in Uvalde, Texas.\\n\\n14 children and one teacher murd…   \n",
       "8       RT @LRiddickESPN: Uh…question …WTF are those of you “in charge” that can make significant change happen in the name of safety ACTUALLY DOIN…   \n",
       "9       @TheUSASingers My daughter had a lockdown incident today at her school today hours before what happened in Texas😩 M… https://t.co/GdKqjKVjb2   \n",
       "10   RT @Gisele23935327: Who did not shoot up a school today?\\nA border crosser, transgender, or gay,\\nIt wasn’t Antifa, not BLM,\\nNot Hunter Biden…   \n",
       "11      RT @MichaelSteele: 14 children and a teacher have been killed in a shooting at an elementary school in Texas.  Again, another school shooti…   \n",
       "12      RT @ABCPolitics: Sen. Chris Murphy delivers remarks on Uvalde, Texas elementary school shooting: “What are we doing? What are we doing?…Thi…   \n",
       "13      RT @glowinasia: and if ur a non american saying some shit like i’m glad i’m not american or pulling the school shooting “jokes” during even…   \n",
       "14                                                                                                                        @iiTorchTv school shooting   \n",
       "15  RT @KaufmanAbrams: A horrific massacre at a Texas Grammar School. My children grown &amp; have grand children even if I didn’t I Have said in p…   \n",
       "16      RT @OccupyDemocrats: BREAKING NEWS: Texas’ gun-obsessed Governor Greg Abbott confirms that 14 children and two adults were shot dead by a m…   \n",
       "17                                      RT @Meidas_Adrienne: If you want school shootings to stop then don’t don’t vote for a republican ever again.   \n",
       "18      RT @ABCPolitics: Sen. Chris Murphy delivers remarks on Uvalde, Texas elementary school shooting: “What are we doing? What are we doing?…Thi…   \n",
       "19  RT @KingJames: My thoughts and prayers goes out to the families of love ones loss &amp; injured at Robb Elementary School in Uvalde, TX! Like w…   \n",
       "\n",
       "     retweeted_from retweeted  \n",
       "0               ABC        RT  \n",
       "1              None            \n",
       "2        jaketapper        RT  \n",
       "3              None            \n",
       "4         Josh_Moon        RT  \n",
       "5        Jim_Jordan        RT  \n",
       "6        meganbang3        RT  \n",
       "7      jewishaction        RT  \n",
       "8      LRiddickESPN        RT  \n",
       "9              None            \n",
       "10   Gisele23935327        RT  \n",
       "11    MichaelSteele        RT  \n",
       "12      ABCPolitics        RT  \n",
       "13       glowinasia        RT  \n",
       "14             None            \n",
       "15    KaufmanAbrams        RT  \n",
       "16  OccupyDemocrats        RT  \n",
       "17  Meidas_Adrienne        RT  \n",
       "18      ABCPolitics        RT  \n",
       "19        KingJames        RT  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub[['text','retweeted_from','retweeted']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9104a553-72d9-4fc8-a9fa-0fc2405794f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking the lang column\n",
    "### only 'en' is in the column, drop this \n",
    "sub['lang'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9db8768-b98f-4abe-9ca1-03acd23d9806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @ABC: “Why are you here?!\"\\n\\nA furious Sen. Chris Murphy demands answers from senators following Texas school shooting.\\n\\n“Why do you spen…</td>\n",
       "      <td>“Why are you here?!\"\\n\\nA furious Sen. Chris Murphy demands answers from senators following Texas school shooting.\\n\\n“Why do you spend all this time running for the United States Senate...if your answer, is as the slaughter increases, as our kids run for their lives—we do nothing?” https://t.co/9fkJ13vWGd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Indiana High School Softball | Live Streaming\\nTBA vs Fishers\\nEastbrook vs Oak Hill\\nTBA vs Wabash\\nSouth Newton vs Cl… https://t.co/QvvQQUUOG8</td>\n",
       "      <td>Indiana High School Softball | Live Streaming\\nTBA vs Fishers\\nEastbrook vs Oak Hill\\nTBA vs Wabash\\nSouth Newton vs Clinton Central\\nTBA vs Muncie Central\\nTBA vs Shakamak\\nWatch Live Here : https://t.co/WLu5HSoUK6\\ntoday @ 7p https://t.co/epcCQgjoSb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RT @jaketapper: Fifteen have been killed in a shooting at Robb elementary school, according to Governor Greg Abbott —  14 students and 1 te…</td>\n",
       "      <td>Fifteen have been killed in a shooting at Robb elementary school, according to Governor Greg Abbott —  14 students and 1 teacher. \\n \\nAbbott said the shooter is also deceased.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Uvalde is just another reason why you should home school your kids. Exposing your kids to the degenerate version o… https://t.co/KiEpSzUJtf</td>\n",
       "      <td>#Uvalde is just another reason why you should home school your kids. Exposing your kids to the degenerate version of America the left has created is almost child abuse at this point.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @Josh_Moon: 14 dead elementary school kids. 14. Not from CRT. Or \"woke\" history. Which red states took great pains to ban. But from our…</td>\n",
       "      <td>14 dead elementary school kids. 14. Not from CRT. Or \"woke\" history. Which red states took great pains to ban. But from our infatuation with goddamn guns. How is it possible that our children dying at school isn't too much?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @Jim_Jordan: Last week we learned:\\n\\n-Hillary Clinton ordered the dissemination of the Trump/Alfa Bank hoax.\\n\\n-President Biden thanked NS…</td>\n",
       "      <td>Last week we learned:\\n\\n-Hillary Clinton ordered the dissemination of the Trump/Alfa Bank hoax.\\n\\n-President Biden thanked NSBA for writing a letter targeting parents at school board meetings.\\n\\n-And Democrats think men can get pregnant.\\n\\nCan’t make it up.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RT @meganbang3: My son was not allowed to walk in his high school graduation yesterday because of his beaded cap and eagle feather. They wa…</td>\n",
       "      <td>My son was not allowed to walk in his high school graduation yesterday because of his beaded cap and eagle feather. They wanted him to put on a plain one and he said nope not walking then. I’m so proud of him and furious at the same time. https://t.co/wbIy5gjjnX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @jewishaction: We're horrified by the news of the shooting at Robb Elementary School in Uvalde, Texas.\\n\\n14 children and one teacher murd…</td>\n",
       "      <td>We're horrified by the news of the shooting at Robb Elementary School in Uvalde, Texas.\\n\\n14 children and one teacher murdered. Multiple others injured and traumatized.\\n\\nWe must act to end gun violence. Our children and our teachers — and all of us — deserve to live and thrive.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @LRiddickESPN: Uh…question …WTF are those of you “in charge” that can make significant change happen in the name of safety ACTUALLY DOIN…</td>\n",
       "      <td>Uh…question …WTF are those of you “in charge” that can make significant change happen in the name of safety ACTUALLY DOING help make it so our children don’t DIE BY GETTING SHOT in school! WHAT ARE YOU ACTUALLY DOING ABOUT IT?!?!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@TheUSASingers My daughter had a lockdown incident today at her school today hours before what happened in Texas😩 M… https://t.co/GdKqjKVjb2</td>\n",
       "      <td>@TheUSASingers My daughter had a lockdown incident today at her school today hours before what happened in Texas😩 My daughter asked me why in our neighborhood. I sadly had to tell her it’s not about black or white, rich or poor neighborhoods it’s ALL OF Americas problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                               text  \\\n",
       "0  RT @ABC: “Why are you here?!\"\\n\\nA furious Sen. Chris Murphy demands answers from senators following Texas school shooting.\\n\\n“Why do you spen…   \n",
       "1  Indiana High School Softball | Live Streaming\\nTBA vs Fishers\\nEastbrook vs Oak Hill\\nTBA vs Wabash\\nSouth Newton vs Cl… https://t.co/QvvQQUUOG8   \n",
       "2      RT @jaketapper: Fifteen have been killed in a shooting at Robb elementary school, according to Governor Greg Abbott —  14 students and 1 te…   \n",
       "3      #Uvalde is just another reason why you should home school your kids. Exposing your kids to the degenerate version o… https://t.co/KiEpSzUJtf   \n",
       "4       RT @Josh_Moon: 14 dead elementary school kids. 14. Not from CRT. Or \"woke\" history. Which red states took great pains to ban. But from our…   \n",
       "5  RT @Jim_Jordan: Last week we learned:\\n\\n-Hillary Clinton ordered the dissemination of the Trump/Alfa Bank hoax.\\n\\n-President Biden thanked NS…   \n",
       "6      RT @meganbang3: My son was not allowed to walk in his high school graduation yesterday because of his beaded cap and eagle feather. They wa…   \n",
       "7    RT @jewishaction: We're horrified by the news of the shooting at Robb Elementary School in Uvalde, Texas.\\n\\n14 children and one teacher murd…   \n",
       "8      RT @LRiddickESPN: Uh…question …WTF are those of you “in charge” that can make significant change happen in the name of safety ACTUALLY DOIN…   \n",
       "9      @TheUSASingers My daughter had a lockdown incident today at her school today hours before what happened in Texas😩 M… https://t.co/GdKqjKVjb2   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                            tweet_text  \n",
       "0  “Why are you here?!\"\\n\\nA furious Sen. Chris Murphy demands answers from senators following Texas school shooting.\\n\\n“Why do you spend all this time running for the United States Senate...if your answer, is as the slaughter increases, as our kids run for their lives—we do nothing?” https://t.co/9fkJ13vWGd  \n",
       "1                                                          Indiana High School Softball | Live Streaming\\nTBA vs Fishers\\nEastbrook vs Oak Hill\\nTBA vs Wabash\\nSouth Newton vs Clinton Central\\nTBA vs Muncie Central\\nTBA vs Shakamak\\nWatch Live Here : https://t.co/WLu5HSoUK6\\ntoday @ 7p https://t.co/epcCQgjoSb  \n",
       "2                                                                                                                                     Fifteen have been killed in a shooting at Robb elementary school, according to Governor Greg Abbott —  14 students and 1 teacher. \\n \\nAbbott said the shooter is also deceased.  \n",
       "3                                                                                                                               #Uvalde is just another reason why you should home school your kids. Exposing your kids to the degenerate version of America the left has created is almost child abuse at this point.  \n",
       "4                                                                                      14 dead elementary school kids. 14. Not from CRT. Or \"woke\" history. Which red states took great pains to ban. But from our infatuation with goddamn guns. How is it possible that our children dying at school isn't too much?  \n",
       "5                                                Last week we learned:\\n\\n-Hillary Clinton ordered the dissemination of the Trump/Alfa Bank hoax.\\n\\n-President Biden thanked NSBA for writing a letter targeting parents at school board meetings.\\n\\n-And Democrats think men can get pregnant.\\n\\nCan’t make it up.  \n",
       "6                                               My son was not allowed to walk in his high school graduation yesterday because of his beaded cap and eagle feather. They wanted him to put on a plain one and he said nope not walking then. I’m so proud of him and furious at the same time. https://t.co/wbIy5gjjnX  \n",
       "7                            We're horrified by the news of the shooting at Robb Elementary School in Uvalde, Texas.\\n\\n14 children and one teacher murdered. Multiple others injured and traumatized.\\n\\nWe must act to end gun violence. Our children and our teachers — and all of us — deserve to live and thrive.  \n",
       "8                                                                                Uh…question …WTF are those of you “in charge” that can make significant change happen in the name of safety ACTUALLY DOING help make it so our children don’t DIE BY GETTING SHOT in school! WHAT ARE YOU ACTUALLY DOING ABOUT IT?!?!  \n",
       "9                                       @TheUSASingers My daughter had a lockdown incident today at her school today hours before what happened in Texas😩 My daughter asked me why in our neighborhood. I sadly had to tell her it’s not about black or white, rich or poor neighborhoods it’s ALL OF Americas problem  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### checking possible text columns for the tweet content \n",
    "### text and tweet_text are basically the same, except that text also contains the retweeted account. \n",
    "### I will keep only the tweet_text column\n",
    "sub[['text', 'tweet_text']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9aec70e8-c690-460c-9ccc-08dba7cefdf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>name</th><th>screen_name</th></tr>\n",
       "<tr><td>shiaoma</td><td>shiaoma</td></tr>\n",
       "<tr><td>High School Sports</td><td>Gabriel50407921</td></tr>\n",
       "<tr><td>FullyDedicated2Thee</td><td>2Short2Sweet</td></tr>\n",
       "<tr><td>Knowledge And Faith</td><td>LBR_TY</td></tr>\n",
       "<tr><td>✨noelain✨</td><td>disneymama0113</td></tr>\n",
       "<tr><td>Earthangel</td><td>Earthangel7558</td></tr>\n",
       "<tr><td>Salvadorean Poodl...</td><td>Lizzy9839</td></tr>\n",
       "<tr><td>la perra ivette</td><td>Guti_0730</td></tr>\n",
       "<tr><td>Alex Calix</td><td>jacalix90</td></tr>\n",
       "<tr><td>Lorraine L. Hayden</td><td>Ms_Raine</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+---------------+\n",
       "|                name|    screen_name|\n",
       "+--------------------+---------------+\n",
       "|             shiaoma|        shiaoma|\n",
       "|  High School Sports|Gabriel50407921|\n",
       "| FullyDedicated2Thee|   2Short2Sweet|\n",
       "| Knowledge And Faith|         LBR_TY|\n",
       "|           ✨noelain✨| disneymama0113|\n",
       "|          Earthangel| Earthangel7558|\n",
       "|Salvadorean Poodl...|      Lizzy9839|\n",
       "|     la perra ivette|      Guti_0730|\n",
       "|          Alex Calix|      jacalix90|\n",
       "|  Lorraine L. Hayden|       Ms_Raine|\n",
       "+--------------------+---------------+"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.select(['user.name', 'user.screen_name']).limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89efc987-b261-489c-b24f-66ec807d3740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tweets_df.select([tweets_df.created_at,\n",
    "                      tweets_df.id.alias('tweet_id'),\n",
    "                      tweets_df.tweet_text,\n",
    "                      tweets_df.user['id'].alias('user_id'),\n",
    "                      tweets_df.user['name'].alias('user_name'),\n",
    "                      tweets_df.user['screen_name'].alias('user_screen_name'),\n",
    "                      tweets_df.user['location'].alias('user_location'),\n",
    "                      tweets_df.user['description'].alias('user_description'),\n",
    "                      tweets_df.place['country'].alias('tweet_country'),\n",
    "                      tweets_df.place['full_name'].alias('tweet_location'),\n",
    "                      tweets_df.retweeted_status['retweet_count'],\n",
    "                      tweets_df.retweeted_from,\n",
    "                      tweets_df.retweeted,\n",
    "                      tweets_df.favorite_count,\n",
    "                      tweets_df.timestamp_ms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2e225c-8402-4f6d-ae28-552692ebb1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- created_at: string (nullable = true)\n",
      " |-- tweet_id: long (nullable = true)\n",
      " |-- tweet_text: string (nullable = true)\n",
      " |-- user_id: long (nullable = true)\n",
      " |-- user_name: string (nullable = true)\n",
      " |-- user_screen_name: string (nullable = true)\n",
      " |-- user_location: string (nullable = true)\n",
      " |-- user_description: string (nullable = true)\n",
      " |-- tweet_country: string (nullable = true)\n",
      " |-- tweet_location: string (nullable = true)\n",
      " |-- retweeted_status.retweet_count: long (nullable = true)\n",
      " |-- retweeted_from: string (nullable = true)\n",
      " |-- retweeted: string (nullable = true)\n",
      " |-- favorite_count: long (nullable = true)\n",
      " |-- timestamp_ms: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#### Checking the schema of this filtered dataset\n",
    "\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96895d60-56a7-4b34-b046-9b567e0de427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border='1'>\n",
       "<tr><th>created_at</th><th>tweet_id</th><th>tweet_text</th><th>user_id</th><th>user_name</th><th>user_screen_name</th><th>user_location</th><th>user_description</th><th>tweet_country</th><th>tweet_location</th><th>retweeted_status.retweet_count</th><th>retweeted_from</th><th>retweeted</th><th>favorite_count</th></tr>\n",
       "<tr><td>Wed May 25 00:43:...</td><td>1529261786217689090</td><td>Get involved. Get...</td><td>241666780</td><td>Rachel Heine</td><td>RachelHeine</td><td>Los Angeles, CA</td><td>🧛🏻‍♀️ vp of bra...</td><td>null</td><td>null</td><td>16</td><td>shannonrwatts</td><td>RT</td><td>0</td></tr>\n",
       "<tr><td>Wed May 25 00:43:...</td><td>1529261786247069697</td><td>A westerner will ...</td><td>1356163969594097665</td><td>jameel Khan</td><td>jameelK60094344</td><td>null</td><td>Nothing hurts a g...</td><td>null</td><td>null</td><td>2901</td><td>lapatina_</td><td>RT</td><td>0</td></tr>\n",
       "<tr><td>Wed May 25 00:43:...</td><td>1529261786087800833</td><td>A gun did not gro...</td><td>1518737390386524164</td><td>Mary Ross</td><td>beagle0318</td><td>null</td><td>null</td><td>null</td><td>null</td><td>1138</td><td>ChristianWalk1r</td><td>RT</td><td>0</td></tr>\n",
       "</table>\n"
      ],
      "text/plain": [
       "+--------------------+-------------------+--------------------+------------------+--------------------+----------------+--------------------+--------------------+-------------+--------------+------------------------------+--------------+---------+--------------+\n",
       "|          created_at|           tweet_id|          tweet_text|           user_id|           user_name|user_screen_name|       user_location|    user_description|tweet_country|tweet_location|retweeted_status.retweet_count|retweeted_from|retweeted|favorite_count|\n",
       "+--------------------+-------------------+--------------------+------------------+--------------------+----------------+--------------------+--------------------+-------------+--------------+------------------------------+--------------+---------+--------------+\n",
       "|Wed Apr 13 17:27:...|1514294317271158784|Thank you to @Dea...|748642928466198529|Donnalyn Washingt...|      Notingshaw|                null|#Reviewer #Senior...|         null|          null|                             5|       LizWFab|       RT|             0|\n",
       "|Wed Apr 13 17:27:...|1514294317606649859|Staff in the scho...|          40330082|              Neil D|    NeilDonachie|Whitley Bay, England|Newcastle United ...|         null|          null|                         12804|ExHeadBHandPHS|       RT|             0|\n",
       "|Wed Apr 13 17:27:...|1514294318005207044|i go to school w/...|801837704090677248|             Em 👸🏾|          emviap|       New York, USA|instagram: emmvia...|         null|          null|                          null|          null|         |             0|\n",
       "+--------------------+-------------------+--------------------+------------------+--------------------+----------------+--------------------+--------------------+-------------+--------------+------------------------------+--------------+---------+--------------+"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.limit(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92c4e49b-0857-483e-a995-02d53a345ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99992797"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### To see how many rows we have\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8faecae-cb74-447b-b9de-35f111d40b34",
   "metadata": {},
   "source": [
    "#### Analyzing text data to find the most frequent keywords\n",
    "##### I will use ~10% of the full dataset in this procedure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edf04e5e-4051-409b-8b7b-c9efc64eb7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.limit(10000000)\n",
    "\n",
    "text_rdd = text.rdd.map(lambda x : x['text']).filter(lambda x: x is not None)\n",
    "\n",
    "#### Removing stopwords in the text field \n",
    "\n",
    "StopWords = stopwords.words(\"english\")\n",
    "\n",
    "tokens = text_rdd\\\n",
    "             .map( lambda document: document.strip().lower())\\\n",
    "             .map( lambda document: re.split(\" \", document))\\\n",
    "             .map( lambda word: [x for x in word if x.isalnum()])\\\n",
    "             .map( lambda word: [x for x in word if x not in StopWords])\\\n",
    "             .map( lambda word: [x for x in word if len(x) > 3] ) \\\n",
    "             .map( lambda word: ' '.join(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9d23b2d-78c0-42f2-a690-1b238ad33dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['really believe kids really worry safe school crazy crazy',\n",
       " 'school shootings worried ridiculous',\n",
       " 'teacher mireles killed along least students shooting elementary school']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43cced72-1fae-4e7d-b551-dd7cec120b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.8 ms, sys: 0 ns, total: 15.8 ms\n",
      "Wall time: 81.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wordCounts = tokens.flatMap(lambda text: text.split(' ')) \\\n",
    "                    .map(lambda word: (word, 1)) \\\n",
    "                    .reduceByKey(lambda a, b: a+b)\n",
    "\n",
    "\n",
    "wordCountsSorted = wordCounts.map(lambda x:(x[1],x[0])).sortByKey(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a679f15e-d46c-4d7a-a543-8374f46f6484",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/12/04 00:55:35 WARN org.apache.spark.scheduler.TaskSetManager: Lost task 0.0 in stage 42.0 (TID 69744) (hub-msca-bdp-dphub-students-kaitongh-w-1.c.msca-bdp-students.internal executor 73): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1558, in __getitem__\n",
      "    idx = self.__fields__.index(item)\n",
      "ValueError: 'text' is not in list\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n",
      "    process()\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 594, in process\n",
      "    out_iter = func(split_index, iterator)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n",
      "    return func(split, prev_func(split, iterator))\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 418, in func\n",
      "    return f(iterator)\n",
      "  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2144, in combineLocally\n",
      "    merger.mergeValues(iterator)\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/shuffle.py\", line 240, in mergeValues\n",
      "    for k, v in iterator:\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/tmp/ipykernel_8954/2292434514.py\", line 3, in <lambda>\n",
      "  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1563, in __getitem__\n",
      "    raise ValueError(item)\n",
      "ValueError: text\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n",
      "\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n",
      "\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n",
      "\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n",
      "\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n",
      "\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "\n",
      "22/12/04 00:55:40 ERROR org.apache.spark.scheduler.TaskSetManager: Task 0 in stage 42.0 failed 10 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 42.0 failed 10 times, most recent failure: Lost task 0.9 in stage 42.0 (TID 69753) (hub-msca-bdp-dphub-students-kaitongh-sw-z9wt.c.msca-bdp-students.internal executor 71): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1558, in __getitem__\n    idx = self.__fields__.index(item)\nValueError: 'text' is not in list\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 594, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 418, in func\n    return f(iterator)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2144, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/shuffle.py\", line 240, in mergeValues\n    for k, v in iterator:\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_8954/2292434514.py\", line 3, in <lambda>\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1563, in __getitem__\n    raise ValueError(item)\nValueError: text\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2204)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2225)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2244)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1558, in __getitem__\n    idx = self.__fields__.index(item)\nValueError: 'text' is not in list\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 594, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 418, in func\n    return f(iterator)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2144, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/shuffle.py\", line 240, in mergeValues\n    for k, v in iterator:\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_8954/2292434514.py\", line 3, in <lambda>\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1563, in __getitem__\n    raise ValueError(item)\nValueError: text\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mwordCountsSorted\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/rdd.py:1566\u001b[0m, in \u001b[0;36mRDD.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1563\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1565\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[0;32m-> 1566\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   1569\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/context.py:1233\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;66;03m# Implementation note: This is implemented as a mapPartitions followed\u001b[39;00m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;66;03m# by runJob() in order to avoid having to pass a Python lambda into\u001b[39;00m\n\u001b[1;32m   1231\u001b[0m \u001b[38;5;66;03m# SparkContext#runJob.\u001b[39;00m\n\u001b[1;32m   1232\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[0;32m-> 1233\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py:1304\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1298\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1300\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1301\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1303\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1304\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1308\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/lib/spark/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 42.0 failed 10 times, most recent failure: Lost task 0.9 in stage 42.0 (TID 69753) (hub-msca-bdp-dphub-students-kaitongh-sw-z9wt.c.msca-bdp-students.internal executor 71): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1558, in __getitem__\n    idx = self.__fields__.index(item)\nValueError: 'text' is not in list\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 594, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 418, in func\n    return f(iterator)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2144, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/shuffle.py\", line 240, in mergeValues\n    for k, v in iterator:\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_8954/2292434514.py\", line 3, in <lambda>\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1563, in __getitem__\n    raise ValueError(item)\nValueError: text\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:750)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2304)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2253)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2252)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2252)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1124)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1124)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1124)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2491)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2433)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2422)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:902)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2204)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2225)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2244)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:166)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:750)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1558, in __getitem__\n    idx = self.__fields__.index(item)\nValueError: 'text' is not in list\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 594, in process\n    out_iter = func(split_index, iterator)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2916, in pipeline_func\n    return func(split, prev_func(split, iterator))\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 418, in func\n    return f(iterator)\n  File \"/usr/lib/spark/python/pyspark/rdd.py\", line 2144, in combineLocally\n    merger.mergeValues(iterator)\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/shuffle.py\", line 240, in mergeValues\n    for k, v in iterator:\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"/tmp/ipykernel_8954/2292434514.py\", line 3, in <lambda>\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/types.py\", line 1563, in __getitem__\n    raise ValueError(item)\nValueError: text\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:517)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:652)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:635)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:470)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1211)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.shuffle.sort.BypassMergeSortShuffleWriter.write(BypassMergeSortShuffleWriter.java:134)\n\tat org.apache.spark.shuffle.ShuffleWriteProcessor.write(ShuffleWriteProcessor.scala:59)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99)\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:52)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:131)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:505)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1439)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:508)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "wordCountsSorted.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e568302f-f50d-4506-b376-489317b0d9b6",
   "metadata": {},
   "source": [
    "In the 50 words above, 12 of them are clearly related to education. Which are:\n",
    "\n",
    "school /college /university /student /kids /professor /children /public /teacher /education /elementary /class \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40aefe9-b8e7-41c5-b88a-287350784cc6",
   "metadata": {},
   "source": [
    "#### Discarding irrelevant tweets\n",
    "Irrelevant tweets include those that do not contain the most frequent keywords identified above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f7724a1-4a6a-49af-a4dd-5f5f1202e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### converting the text in the text column to lowercase\n",
    "df = df.withColumn('tweet_text', lower(col('tweet_text')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88b05dcb-5514-4441-9173-f362f2a67b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.filter(df.tweet_text.contains('school')\\\n",
    "                       |df.tweet_text.contains('college')\\\n",
    "                       |df.tweet_text.contains('university')\\\n",
    "                       |df.tweet_text.contains('kids')\\\n",
    "                       |df.tweet_text.contains('professor')\\\n",
    "                       |df.tweet_text.contains('children')\\\n",
    "                       |df.tweet_text.contains('public')\\\n",
    "                       |df.tweet_text.contains('teacher')\\\n",
    "                       |df.tweet_text.contains('education')\\\n",
    "                       |df.tweet_text.contains('elementary')\\\n",
    "                       |df.tweet_text.contains('class')\\\n",
    "                       |df.tweet_text.contains('student'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9007e-038e-4795-835a-d5e4b1b94d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "99100416"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39964af-1bf6-446b-a9d4-de74f4a4b340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "filtered_df.write.format('parquet').\\\n",
    "mode('overwrite').\\\n",
    "save('gs://' + bucket_write + '/' + folder_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8846590-11aa-4416-8566-2939fb8daad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list_blobs(bucket_name=bucket_write, folder_name=folder_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caad0ce2-919c-428b-a689-42df5f45cf09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
